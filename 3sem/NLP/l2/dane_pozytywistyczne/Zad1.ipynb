{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from math import log as ln\n",
    "def loadData(file):\n",
    "    with open(file) as f:\n",
    "        res = f.read()\n",
    "        sents = list ( filter ( lambda x: len(x) > 1, re.split('\\n|\\.|\\!|\\?|\\...', res)))\n",
    "        avg_len = sum ( list ( map ( lambda x : len(x.split()), sents )))\n",
    "    return res.split(), avg_len/len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load1gram(data):\n",
    "    dict_gram = {}\n",
    "    for word in data:\n",
    "        if word not in dict_gram:\n",
    "            dict_gram[word] = 0\n",
    "        dict_gram[word] += 1\n",
    "    return dict_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load2gram(data):\n",
    "    dict_gram = {}\n",
    "    key = data[0]\n",
    "    for word in data[1:]:\n",
    "        if key not in dict_gram:\n",
    "            dict_gram[key] = {}\n",
    "        if word not in dict_gram[key]:\n",
    "            dict_gram[key][word] = 0\n",
    "        dict_gram[key][word] += 1\n",
    "        key = word\n",
    "    return dict_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load3gram(data):\n",
    "    dict_gram = {}\n",
    "    key = (data[0],data[1])\n",
    "    for word in data[2:]:\n",
    "        #print(key)\n",
    "        if key not in dict_gram:\n",
    "            dict_gram[key] = {}\n",
    "        if word not in dict_gram[key]:\n",
    "            dict_gram[key][word] = 0\n",
    "        dict_gram[key][word] += 1\n",
    "        tmp = (key[1],word)\n",
    "        key = tmp\n",
    "    return dict_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_orzeszkowa, avg_o = loadData(\"korpus_orzeszkowej.txt\")\n",
    "data_prus, avg_p = loadData(\"korpus_prusa.txt\")\n",
    "data_sienkiewicz, avg_s = loadData(\"korpus_sienkiewicza.txt\")\n",
    "#print(avg_o)\n",
    "#print(data_orzeszkowa[:100])\n",
    "gram1_orzeszkowa = load1gram(data_orzeszkowa)\n",
    "gram2_orzeszkowa = load2gram(data_orzeszkowa)\n",
    "gram3_orzeszkowa = load3gram(data_orzeszkowa)\n",
    "\n",
    "gram1_prus = load1gram(data_prus)\n",
    "gram2_prus = load2gram(data_prus)\n",
    "gram3_prus = load3gram(data_prus)\n",
    "\n",
    "gram1_sienkiewicz = load1gram(data_sienkiewicz)\n",
    "gram2_sienkiewicz = load2gram(data_sienkiewicz)\n",
    "gram3_sienkiewicz = load3gram(data_sienkiewicz)\n",
    "\n",
    "feature = {'P' : [gram1_prus,gram2_prus,gram3_prus,avg_p], 'O' : [gram1_orzeszkowa,gram2_orzeszkowa,gram3_orzeszkowa,avg_o], 'S' : [gram1_sienkiewicz,gram2_sienkiewicz,gram3_sienkiewicz,avg_s]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes(test):\n",
    "    prob = {i : 0 for i in 'POS'}\n",
    "    data_test, avg_t = loadData(test)\n",
    "    gram1_test = load1gram(data_test)\n",
    "    for w in gram1_test:\n",
    "        for i in 'POS':\n",
    "            if w in feature[i][0]: # unigram w is in gram1_...\n",
    "                prob[i] += ln(feature[i][0][w] / len(feature[i][0]))\n",
    "            else:\n",
    "                prob[i] += ln(1.0 / len(feature[i][0]))\n",
    "                \n",
    "    key = data_test[0]\n",
    "    for w in data_test[1:]:\n",
    "        for i in 'POS':\n",
    "            if key in feature[i][1]:\n",
    "                if w in feature[i][1][key]:\n",
    "                    prob[i] += ln(feature[i][1][key][w] / feature[i][0][key] )\n",
    "                    #prob[i] += ln(feature[i][1][key][w] / len (feature[i][1]) )\n",
    "            else:\n",
    "                prob[i] += (0.3)*ln(1.0 / len(feature[i][0])) \n",
    "        key = w\n",
    "        \n",
    "    key = (data_test[0],data_test[1])\n",
    "    for w in data_test[2:]:\n",
    "        for i in 'POS':\n",
    "            if key in feature[i][2]:\n",
    "                if w in feature[i][2][key]:\n",
    "                    prob[i] += ln(feature[i][2][key][w] / feature[i][1][key[0]][key[1]] )\n",
    "                    #prob[i] += ln(feature[i][2][key][w] / len(feature[i][2]) )\n",
    "            else:\n",
    "                prob[i] += (0.7)*ln(1.0 / len(feature[i][0])) \n",
    "        tmp = (key[1],w)\n",
    "        key = tmp\n",
    "            \n",
    "    for i in 'POS':\n",
    "        prob[i] += ln( feature[i][3] / (feature[i][3] + abs (feature[i][3] - avg_t)  ))\n",
    "        \n",
    "    return max(prob.items(), key = lambda x: x[1])[0] , prob\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "P\n",
      "\n",
      "\n",
      "\n",
      "O\n",
      "O\n",
      "O\n",
      "('S', {'P': -15931.412418476895, 'O': -15494.951623367708, 'S': -15457.475514343894})\n",
      "('S', {'P': -15174.195797178023, 'O': -15005.09511988723, 'S': -14842.318234274057})\n",
      "('S', {'P': -15002.735144027336, 'O': -14740.149391194973, 'S': -14701.601491313382})\n",
      "('S', {'P': -15209.58017658191, 'O': -14972.875711072322, 'S': -14830.259642407102})\n",
      "('S', {'P': -15751.484097648448, 'O': -15651.77173028726, 'S': -15420.429169249992})\n",
      "O\n",
      "O\n",
      "O\n",
      "\n",
      "\n",
      "\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "('P', {'P': -13726.033339251173, 'O': -14100.032324160653, 'S': -13767.404035697646})\n",
      "S\n",
      "('P', {'P': -13102.86641212393, 'O': -13600.324554718007, 'S': -13167.305564294598})\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "('P', {'P': -12583.795054810662, 'O': -12988.44634647526, 'S': -12676.31561618292})\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n",
      "('P', {'P': -12710.79547504893, 'O': -12960.880732758738, 'S': -12740.176223894803})\n",
      "S\n",
      "S\n",
      "S\n",
      "S\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,42,2):\n",
    "    f = f\"testy1/test_prusa{i}.txt\"\n",
    "    res = NaiveBayes(f)\n",
    "    if res[0] == 'P':\n",
    "        print(res[0])\n",
    "    else:\n",
    "        print(res)\n",
    "print('\\n\\n')\n",
    "for i in range(1,23,2):\n",
    "    f = f\"testy1/test_orzeszkowej{i}.txt\"\n",
    "    res = NaiveBayes(f)\n",
    "    if res[0] == 'O':\n",
    "        print(res[0])\n",
    "    else:\n",
    "        print(res)\n",
    "print('\\n\\n')\n",
    "for i in range(1,55,2):\n",
    "    f = f\"testy1/test_sienkiewicza{i}.txt\"\n",
    "    res = NaiveBayes(f)\n",
    "    if res[0] == 'S':\n",
    "        print(res[0])\n",
    "    else:\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
