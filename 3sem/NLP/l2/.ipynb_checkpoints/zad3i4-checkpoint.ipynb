{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_unigrams(file):\n",
    "    K = 5\n",
    "    unigrams = {}\n",
    "    bigrams = {}\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            count = int(line.split()[0])\n",
    "            w1 = line.split()[1]\n",
    "            w2 = line.split()[2]\n",
    "            if count >= K:\n",
    "                \n",
    "                if w1 not in bigrams:\n",
    "                    bigrams[w1] = {}\n",
    "                bigrams[w1][w2] = count\n",
    "                \n",
    "                if w1 not in unigrams:\n",
    "                    unigrams[w1] = 1\n",
    "                if w2 not in unigrams:\n",
    "                    unigrams[w2] = 1\n",
    "                unigrams[w1] += 1\n",
    "                unigrams[w2] += 1\n",
    "    return unigrams,bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams,bigrams = load_unigrams(\"poleval_2grams.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_supertags(file):\n",
    "    d_suf_words = {}\n",
    "    d_tags = {}\n",
    "    d_words = {}\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            t = line.split()[1]\n",
    "            w = line.split()[0]\n",
    "            ws = (\"^\" + w)[-3:]\n",
    "            d_words[w] = t\n",
    "            if ws not in d_suf_words:\n",
    "                d_suf_words[ws] = {}\n",
    "            if t not in d_suf_words:\n",
    "                d_suf_words[ws][t] = 0\n",
    "            d_suf_words[ws][t] += 1\n",
    "            if t not in d_tags:\n",
    "                d_tags[t] = {}\n",
    "            if w in unigrams:\n",
    "                d_tags[t][w] = unigrams[w]\n",
    "            else:\n",
    "                d_tags[t][w] = 1\n",
    "    return (d_suf_words, d_tags, d_words)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_suf_words, d_tags, d_words = load_supertags(\"supertags.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "def gen_tag(d_t):\n",
    "    tags = list (d_t.keys())\n",
    "    prob = list ( d_t.values() )\n",
    "    sum_prob = sum (prob)\n",
    "    r = np.random.choice(len (tags) , p = [p_r/sum_prob for p_r in prob])\n",
    "    return tags[r]\n",
    "\n",
    "def gen_word(tag):\n",
    "    words = list (d_tags[tag].keys())\n",
    "    prob = list ( d_tags[tag].values() )\n",
    "    sum_prob = sum (prob)\n",
    "    r = np.random.choice(len (words) , p = [p_r/sum_prob for p_r in prob])\n",
    "    return words[r]\n",
    "\n",
    "def gen_sen(sen):\n",
    "    s = [i for i in re.split(\"\\s|\\.|\\,\", sen) if len(i) > 0 ]\n",
    "    ans = []\n",
    "    for w in s:\n",
    "        if w in d_words:\n",
    "            ans.append(gen_word(d_words[w]) )\n",
    "        else:\n",
    "            print(\"Could not find word:\", w)\n",
    "            if (\"^\" + w)[-3:] in d_suf_words:\n",
    "                ans.append(gen_word(gen_tag (d_suf_words[(\"^\" + w)[-3:]]) ))\n",
    "    return \" \".join(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mały Piotruś spotkał w niewielkiej restauracyjce wczoraj poznaną koleżankę.\n",
      "polowy poseł zaprosił po niezbędnej formie przykładowo miecioną cenę \n",
      "\n",
      "Pływałem po ogrodzie wraz z moim krokodylem.\n",
      "skarżyłem w zakresie jednoznacznie z tym koniem \n",
      "\n",
      "Potrafię pisać piękne zdania w języku Polskim, ale gorzej mi idzie wczytywanie danych.\n",
      "pięknieję proponować ważne podważenia w odporze kornikowym ale gorzej mi wie obniżenie danych \n",
      "\n",
      "Twierdzenie Bayesa wiąże prawdopodobieństwo warunkowe dwóch zdarzeń.\n",
      "Could not find word: bayesa\n",
      "przemówienie eliasza zawiera aklimatyzowanie pochodne dwóch zasmradzań \n",
      "\n",
      "Cóż potrzeba strzelcowi do zestrzelenia cietrzewia drzemiącego w dżdżysty dzień na strzelistym drzewie.\n",
      "cóż potrzeba performerowi do wyjścia żółwia nadużywającego na polowy dodatek pod zmiennym sąsiedztwie \n",
      "\n",
      "To ważny czynnik podczas suszenia konwekcyjnego, fluidyzacyjnego czy rozpyłowego.\n",
      "Could not find word: fluidyzacyjnego\n",
      "to peruwiański szczebel do stanowiska uznaniowego tego wtedy każdego \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"Mały Piotruś spotkał w niewielkiej restauracyjce wczoraj poznaną koleżankę.\",\n",
    "            \"Pływałem po ogrodzie wraz z moim krokodylem.\",\n",
    "            \"Potrafię pisać piękne zdania w języku Polskim, ale gorzej mi idzie wczytywanie danych.\",\n",
    "            \"Twierdzenie Bayesa wiąże prawdopodobieństwo warunkowe dwóch zdarzeń.\",\n",
    "            \"Cóż potrzeba strzelcowi do zestrzelenia cietrzewia drzemiącego w dżdżysty dzień na strzelistym drzewie.\",\n",
    "            \"To ważny czynnik podczas suszenia konwekcyjnego, fluidyzacyjnego czy rozpyłowego.\"]\n",
    "for s in sentences:\n",
    "    print(s)\n",
    "    print(gen_sen(s.lower()),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sen_tags(sen):\n",
    "    s = [i for i in re.split(\"\\s|\\.|\\,\", sen) if len(i) > 0 ]\n",
    "    tags = []\n",
    "    for w in s:\n",
    "        if w in d_words:\n",
    "            tags.append(d_words[w])\n",
    "        else:\n",
    "            print(\"Could not find word:\", w)\n",
    "            if (\"^\" + w)[-3:] in d_suf_words:\n",
    "                tags.append(gen_tag (d_suf_words[(\"^\" + w)[-3:]]) )\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nexts(word, tag):\n",
    "    ans = []\n",
    "    if word not in bigrams:\n",
    "        return []\n",
    "    nexts = list (bigrams[word].keys())\n",
    "    for n in nexts:\n",
    "        if n in d_words:\n",
    "            if d_words[n] == tag:\n",
    "                ans.append(n)\n",
    "        else:\n",
    "            if (\"^\" + n)[-3:] in d_suf_words:\n",
    "                if gen_tag (d_suf_words[(\"^\" + n)[-3:]]) == tag:\n",
    "                    ans.append(n)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_word_mod(tag):\n",
    "    words = [w for w in list (d_tags[tag].keys()) if w in bigrams]\n",
    "    prob = [d_tags[tag][p] for p in words]\n",
    "    #prob = list ( d_tags[tag].values() )\n",
    "    sum_prob = sum (prob)\n",
    "    if len(words) == 0:\n",
    "        return gen_word(tag)\n",
    "    r = np.random.choice(len (words) , p = [p_r/sum_prob for p_r in prob])\n",
    "    return words[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_word(k, words, tag, last = False):\n",
    "    choices = []\n",
    "    if last:\n",
    "        for w in words:\n",
    "            if w in bigrams:\n",
    "                choices.append(w)\n",
    "    else:\n",
    "        for w in words:\n",
    "            if w in bigrams and len (get_nexts(w , tag)) > 0:\n",
    "                choices.append(w)\n",
    "                \n",
    "    if len(choices) == 0:\n",
    "        return False;\n",
    "    if k:\n",
    "        probs = [bigrams[k][w] for w in choices]\n",
    "    else:\n",
    "        probs = [unigrams[w] for w in choices]\n",
    "        \n",
    "    sum_probs = sum(probs)\n",
    "    r = np.random.choice(len (choices) , p = [p_r/sum_probs for p_r in probs])\n",
    "    return choices[r]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(tags):\n",
    "    c = 0\n",
    "    ans = []\n",
    "    words = list (d_tags[tags[0]].keys())\n",
    "    w = rand_word(False, words, tags[1])\n",
    "    \n",
    "    if not w:\n",
    "        w = gen_word_mod(tags[0])\n",
    "        c += 1\n",
    "        ans += [\"|\"] + [w]\n",
    "    else: \n",
    "        ans.append(w)\n",
    "        \n",
    "    for i in range (1, len(tags) - 1):\n",
    "        words = get_nexts(w, tags[i])\n",
    "        if len(words) == 0:\n",
    "            new_w = False\n",
    "        else:\n",
    "            new_w = rand_word(w, words, tags[i + 1])\n",
    "        w = new_w\n",
    "        if not w:\n",
    "            w = gen_word_mod(tags[i])\n",
    "            c += 1\n",
    "            ans += [\"|\"] + [w]\n",
    "        else: \n",
    "            ans.append(w)\n",
    "            \n",
    "    words = get_nexts(w, tags[-1])\n",
    "    if len(words) == 0:\n",
    "        new_w = False\n",
    "    else:\n",
    "        new_w = rand_word(w, words, tags[0], True)\n",
    "    w = new_w\n",
    "    if not w:\n",
    "        w = gen_word(tags[-1])\n",
    "        c += 1\n",
    "        ans += [\"|\"] + [w]\n",
    "    else: \n",
    "        ans.append(w)\n",
    "    return \" \".join(ans) , c\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_best(sen):\n",
    "    tags = sen_tags(sen)\n",
    "    best_sentence = []\n",
    "    best_score = 100\n",
    "    for i in range(10):\n",
    "        s,c = generator(tags)\n",
    "        if c == 0:\n",
    "            return s\n",
    "        if c < best_score:\n",
    "            best_sentence = s\n",
    "            best_score = c\n",
    "    return best_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mały Piotruś spotkał w niewielkiej restauracyjce wczoraj poznaną koleżankę.\n",
      "szkolny kolega powiedział w niezamożnej rodzinie bardzo znaną osobę \n",
      "\n",
      "Pływałem po ogrodzie wraz z moim krokodylem.\n",
      "chciałem na razie wyraźnie z tym wirusem \n",
      "\n",
      "Potrafię pisać piękne zdania w języku Polskim, ale gorzej mi idzie wczytywanie danych.\n",
      "mogę wykonywać wszelkie działania pod dniu innym ale | gorzej | mi zależy bezpieczeństwo danych \n",
      "\n",
      "Twierdzenie Bayesa wiąże prawdopodobieństwo warunkowe dwóch zdarzeń.\n",
      "Could not find word: bayesa\n",
      "miejsce nauczyciela reguluje rozporządzenie | teoretyczne | czterech ugrupowań \n",
      "\n",
      "Cóż potrzeba strzelcowi do zestrzelenia cietrzewia drzemiącego w dżdżysty dzień na strzelistym drzewie.\n",
      "| cóż | szkoda | właścicielowi przez miasta | żółwia | rozgrywającego w banalny przykład w całym społeczeństwie \n",
      "\n",
      "To ważny czynnik podczas suszenia konwekcyjnego, fluidyzacyjnego czy rozpyłowego.\n",
      "Could not find word: fluidyzacyjnego\n",
      "to znikomy wpływ do budownictwa | ponownego | nieprawniczego | czy innego \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in sentences:\n",
    "    print(s)\n",
    "    print(gen_best(s.lower()),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
