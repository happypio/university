{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "#print(unidecode(\"ąąąBZWDAWD\").lower())\n",
    "def load_data(file):\n",
    "    ans = []\n",
    "    with open(file) as f:\n",
    "        for i in range(10**6):\n",
    "            line = f.readline()\n",
    "            ans += line.split()\n",
    "    return ans\n",
    "unigrams = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_alnum(w):\n",
    "    return ''.join(filter(str.isalnum, w))\n",
    "def generate_1grams(data):\n",
    "    for word in data:\n",
    "        word = convert_to_alnum(word)\n",
    "        norm_word = convert_to_alnum( unidecode(word).lower() )\n",
    "        if norm_word != '':\n",
    "            if norm_word not in unigrams:\n",
    "                unigrams[norm_word] = {}\n",
    "            if word not in unigrams[norm_word]:\n",
    "                unigrams[norm_word][word] = 0\n",
    "            unigrams[norm_word][word] += 1\n",
    "\n",
    "def load_Ngrams(file):\n",
    "    K = 5\n",
    "    bigrams = {}\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            count = int(line.split()[0])\n",
    "            w1 = convert_to_alnum(line.split()[1])\n",
    "            w2 = convert_to_alnum(line.split()[2])\n",
    "            if count >= K:\n",
    "                \n",
    "                if w1 not in bigrams:\n",
    "                    bigrams[w1] = {}\n",
    "                bigrams[w1][w2] = count\n",
    "                \n",
    "                norm_word1 = convert_to_alnum(unidecode(w1).lower() )\n",
    "                norm_word2 = convert_to_alnum(unidecode(w2).lower() )\n",
    "                if norm_word1 != '':\n",
    "                    if norm_word1 not in unigrams:\n",
    "                        unigrams[norm_word1] = {}\n",
    "                    if w1 not in unigrams[norm_word1]:\n",
    "                        unigrams[norm_word1][w1] = 0\n",
    "                    unigrams[norm_word1][w1] += 1\n",
    "                if norm_word2 != '':\n",
    "                    if norm_word2 not in unigrams:\n",
    "                        unigrams[norm_word2] = {}\n",
    "                    if w2 not in unigrams[norm_word2]:\n",
    "                        unigrams[norm_word2][w2] = 0\n",
    "                    unigrams[norm_word2][w2] += 1\n",
    "    return bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate2grams(data):\n",
    "    bigrams_u = {}\n",
    "    key = data[0]\n",
    "    key = convert_to_alnum(key)\n",
    "    norm_key = convert_to_alnum( unidecode(key).lower() )\n",
    "    for word in data[1:]:\n",
    "        word = convert_to_alnum(word)\n",
    "        norm_word = convert_to_alnum( unidecode(word).lower() )\n",
    "        if norm_key not in bigrams_u:\n",
    "            bigrams_u[norm_key] = {}\n",
    "        if norm_word not in bigrams_u[norm_key]:\n",
    "            bigrams_u[norm_key][norm_word] = {}\n",
    "        if (key,word) not in bigrams_u[norm_key][norm_word]:\n",
    "            bigrams_u[norm_key][norm_word][(key,word)] = 0\n",
    "        bigrams_u[norm_key][norm_word][(key,word)] += 1\n",
    "        key = word\n",
    "        norm_key = norm_word\n",
    "    return bigrams_u\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tests(file):\n",
    "    ans = []\n",
    "    with open(file) as f:\n",
    "        for i in range(10**6 + 2*10**5):\n",
    "            line = f.readline()\n",
    "            if i >= 10**6:\n",
    "                ans.append(line.split())\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "good_names = {}\n",
    "def load_polimorfologik(file):\n",
    "    with open(file) as f:\n",
    "        for i in range(10**6):\n",
    "            line = f.readline()\n",
    "            if line[0].isupper():\n",
    "                word = re.split('\\;',line)[1]\n",
    "                norm_word = convert_to_alnum( unidecode(word).lower() )\n",
    "                if norm_word not in good_names:\n",
    "                    good_names[norm_word] = {}\n",
    "                good_names[norm_word][word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_polimorfologik(\"polimorfologik-2.1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = load_tests(\"polish_corpora.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"polish_corpora.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_1grams(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_u = generate2grams(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = load_Ngrams('poleval_2grams.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def norm_sen(s):\n",
    "    ans = []\n",
    "    for w in s:\n",
    "        tmp = convert_to_alnum(unidecode(w).lower())\n",
    "        if len(tmp) > 0:\n",
    "            ans.append(tmp)\n",
    "    return ans\n",
    "\n",
    "def find_word(w,bef = False,nxt = False):\n",
    "    #print(w, bef, nxt)\n",
    "    ws = list(unigrams[w].keys())\n",
    "    cs = list(unigrams[w].values())\n",
    "    words_tmp = [(cs[i],ws[i]) for i in range(len(ws))]\n",
    "    words_tmp.sort(reverse = True)\n",
    "    words = [words_tmp[i][1] for i in range(len(ws))]\n",
    "    if words[0][0].isupper():\n",
    "        return words[0]\n",
    "    if len(words) > 1 and words[1][0].isupper() and words_tmp[0][0] - words_tmp[1][0] < 10:\n",
    "        #if len(words[1]) > 1 and not words[1][1].isupper():\n",
    "        return words[1]\n",
    "    if all(words_tmp[0][0] >= 9*i[0] for i in words_tmp if i != words_tmp[0]):\n",
    "        return words[0]\n",
    "    best = []\n",
    "    best_nxt = []\n",
    "    best_bef = []\n",
    "    bef_s = set()\n",
    "    nxt_s = set()\n",
    "    upper_cases_b = []\n",
    "    upper_cases_a = []\n",
    "    if nxt:\n",
    "        nxt_b = find_word(nxt)\n",
    "    for e in words:\n",
    "        t = convert_to_alnum( e.lower() )\n",
    "        tb = unidecode(bef.lower())\n",
    "        if bef:\n",
    "            if bef in bigrams and t in bigrams[bef] and bigrams[bef][t] not in bef_s:\n",
    "                best_bef.append((111*bigrams[bef][t], e))\n",
    "                bef_s.add(bigrams[bef][t])\n",
    "            if  tb in bigrams_u and t in bigrams_u[tb] and (bef,e) in bigrams_u[tb][t]:\n",
    "                upper_cases_b.append(bigrams_u[tb][t][(tb,t)], e)\n",
    "                \n",
    "        if nxt:\n",
    "            if t in bigrams and nxt_b in bigrams[t] and bigrams[t][nxt_b] not in nxt_s:\n",
    "                best_nxt.append((bigrams[t][nxt_b], e))\n",
    "                nxt_s.add(bigrams[t][nxt_b])\n",
    "        \n",
    "            if t in bigrams_u and nxt in bigrams_u[t] and (e,nxt_b) in bigrams_u[t][nxt]:\n",
    "                upper_cases_a.append(bigrams_u[t][nxt][(e,nxt_b)], e)\n",
    "                \n",
    "    upper_cases_b.sort(reverse = True)\n",
    "    upper_cases_a.sort(reverse = True)\n",
    "    best_bef.sort(reverse = True)\n",
    "    best_nxt.sort(reverse = True)\n",
    "    #if w == 'dbac':\n",
    "        #print(best_bef, best_nxt)\n",
    "        #print(words)\n",
    "    if len(best_bef) > 1 and best_bef[0][0] > 10*best_bef[1][0]:\n",
    "        best = best_bef\n",
    "    else:\n",
    "        if len(best_nxt) > 1 and len(best_bef) > 1 and best_nxt[0][0] > 10*best_nxt[1][0]:\n",
    "            best = best_nxt\n",
    "        else:\n",
    "            best = best_bef + best_nxt\n",
    "    best.sort(reverse = True)\n",
    "    #r = np.random.choice(len(words), p = [p_r/sum_probs for p_r in probs])\n",
    "    if len(best) > 0:\n",
    "        if best[0][1][0].upper() + best[0][1][1:] == \n",
    "        return best[0][1]\n",
    "    return words[0]\n",
    "\n",
    "def sen_restoration(s):\n",
    "    ans = []\n",
    "    for i in range(len(s)):\n",
    "        #print(s[i])\n",
    "        bef = False\n",
    "        nxt = False\n",
    "        if i < len(s) - 1:\n",
    "            nxt = s[i + 1].lower()\n",
    "        if i > 0:\n",
    "            bef = ans[i - 1].lower()\n",
    "        if nxt not in unigrams:\n",
    "            nxt = False\n",
    "        if s[i] not in unigrams:\n",
    "            new_w = s[i]\n",
    "        else:\n",
    "            new_w = find_word(s[i],bef,nxt)\n",
    "        if len(ans) == 0:\n",
    "            new_w = new_w[0].upper() + new_w[1:]\n",
    "        ans.append(new_w)\n",
    "    return ans\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def good_sen(s):\n",
    "    ans = []\n",
    "    for w in s:\n",
    "        tmp = convert_to_alnum(w)\n",
    "        if len(tmp) > 0:\n",
    "            ans.append(tmp)\n",
    "    return ans\n",
    "\n",
    "def score(good_sen, restorated_sen):\n",
    "    g1 = 0\n",
    "    g2 = 0\n",
    "    for i in range(len(good_sen)):\n",
    "        if good_sen[i].lower() == restorated_sen[i].lower():\n",
    "            g1 += 1\n",
    "        if good_sen[i] == restorated_sen[i]:\n",
    "            g2 += 1\n",
    "        else:\n",
    "            print(restorated_sen)\n",
    "            print(good_sen)\n",
    "            #print(restorated_sen[i],good_sen[i])\n",
    "        \n",
    "    a = g1 / len(good_sen)\n",
    "    b = g2 / len(good_sen)\n",
    "    return math.sqrt(a*b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Na', 'jesieni', '1980', 'został', 'członkiem', 'zespołu', 'przygotowującego', 'do', 'druku', 'tygodnika', 'Solidarność', 'szefem', 'zespołu', 'był', 'Jerzy', 'Zieleński']\n",
      "['Na', 'jesieni', '1980', 'został', 'członkiem', 'zespołu', 'przygotowującego', 'do', 'druku', 'Tygodnika', 'Solidarność', 'szefem', 'zespołu', 'był', 'Jerzy', 'Zieleński']\n",
      "0.9971132578683505\n"
     ]
    }
   ],
   "source": [
    "summ = 0\n",
    "n = 0\n",
    "for t in tests:\n",
    "    restorated_s = sen_restoration(norm_sen(t))\n",
    "    good_s = good_sen(t)\n",
    "    n += 1\n",
    "    summ += score(good_s, restorated_s)\n",
    "    if n > 10:\n",
    "        break\n",
    "print(summ / n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Tygodnika': 20, 'tygodnika': 129, 'TYGODNIKA': 2}\n",
      "{'solidarność': 345, 'Solidarność': 724, 'SOLIDARNOŚĆ': 4, 'Solidarnosc': 4, 'solidarnosc': 1}\n"
     ]
    }
   ],
   "source": [
    "print(unigrams['tygodnika'])\n",
    "print(unigrams['solidarnosc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = \"Chociaż znajdują się one na dwóch różnych krańcach świata, są niemal identyczne, bez własnego wizerunku, krajobrazu, atmosfery.\".split()\n",
    "#pd = \"Mimo, iż takie miejsca tracą powoli dawną popularność, wielu współczesnym działaczom polskiej turystyki marzą się podobne widoki w Polsce i chcą przekształcić często niepowtarzalny krajobraz w betonowe ośrodki rozrywki, sportu i wypoczynku, do których za kilkadziesiąt lat nikt nie będzie chciał przyjeżdżać.\".split()\n",
    "pd =\"Zabudowa krajobrazu prowadzi na ogół do urbanizacji terenów turystycznych, wskutek czego powstają wielkie miasta turystyczne, tzw. quasi-miasta, takie jak większość kurortów na Costa Brava w Hiszpanii, Acapulco lub Cancon w Meksyku.\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zabudowa', 'krajobrazu', 'prowadzi', 'na', 'ogol', 'do', 'urbanizacji', 'terenow', 'turystycznych', 'wskutek', 'czego', 'powstaja', 'wielkie', 'miasta', 'turystyczne', 'tzw', 'quasimiasta', 'takie', 'jak', 'wiekszosc', 'kurortow', 'na', 'costa', 'brava', 'w', 'hiszpanii', 'acapulco', 'lub', 'cancon', 'w', 'meksyku']\n"
     ]
    }
   ],
   "source": [
    "w = norm_sen(pd)\n",
    "print(w)\n",
    "#print(sen_restoration(w))\n",
    "#print(score(good_sen(pd), sen_restoration(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649\n",
      "18\n",
      "2048\n",
      "2967\n",
      "{'Zieleński': 2, 'zieleński': 3}\n"
     ]
    }
   ],
   "source": [
    "print(bigrams['to']['okazja'])\n",
    "print(bigrams['to']['okazją'])\n",
    "print(bigrams['okazja']['do'])\n",
    "print(bigrams['okazją']['do'])\n",
    "print(unigrams['zielenski'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8107\n",
      "18667\n"
     ]
    }
   ],
   "source": [
    "print(bigrams['nad']['tą'])\n",
    "print(bigrams['ta']['ustawa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
